{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install simpletransformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-15T15:27:17.806955Z","iopub.execute_input":"2023-09-15T15:27:17.807265Z","iopub.status.idle":"2023-09-15T15:27:48.182302Z","shell.execute_reply.started":"2023-09-15T15:27:17.807230Z","shell.execute_reply":"2023-09-15T15:27:48.181154Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting simpletransformers\n  Downloading simpletransformers-0.64.3-py3-none-any.whl (250 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.8/250.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (1.23.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (2.31.0)\nRequirement already satisfied: tqdm>=4.47.0 in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (4.65.0)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (2023.6.3)\nCollecting transformers>=4.31.0 (from simpletransformers)\n  Downloading transformers-4.33.1-py3-none-any.whl (7.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (2.1.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (1.11.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (1.2.2)\nCollecting seqeval (from simpletransformers)\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (2.12.3)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (1.5.3)\nRequirement already satisfied: tokenizers in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (0.13.3)\nRequirement already satisfied: wandb>=0.10.32 in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (0.15.5)\nCollecting streamlit (from simpletransformers)\n  Downloading streamlit-1.26.0-py2.py3-none-any.whl (8.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (0.1.99)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (0.16.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (6.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (0.3.1)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (8.1.3)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (3.1.31)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (1.27.1)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (0.4.0)\nRequirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (0.1.2)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (1.3.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (59.8.0)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (3.20.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->simpletransformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->simpletransformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->simpletransformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->simpletransformers) (2023.5.7)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (0.3.6)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (2023.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (3.8.4)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (0.18.0)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->simpletransformers) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->simpletransformers) (2023.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->simpletransformers) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->simpletransformers) (3.1.0)\nRequirement already satisfied: altair<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (5.0.1)\nRequirement already satisfied: blinker<2,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (1.6.2)\nRequirement already satisfied: cachetools<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (4.2.4)\nRequirement already satisfied: importlib-metadata<7,>=1.4 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (6.7.0)\nRequirement already satisfied: pillow<10,>=7.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (9.5.0)\nRequirement already satisfied: pympler<2,>=0.9 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (1.0.1)\nRequirement already satisfied: rich<14,>=10.14.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (13.4.2)\nRequirement already satisfied: tenacity<9,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (8.2.2)\nRequirement already satisfied: toml<2,>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (0.10.2)\nRequirement already satisfied: typing-extensions<5,>=4.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (4.6.3)\nCollecting tzlocal<5,>=1.1 (from streamlit->simpletransformers)\n  Downloading tzlocal-4.3.1-py3-none-any.whl (20 kB)\nCollecting validators<1,>=0.2 (from streamlit->simpletransformers)\n  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\nCollecting pydeck<1,>=0.8 (from streamlit->simpletransformers)\n  Downloading pydeck-0.8.0-py2.py3-none-any.whl (4.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (6.3.2)\nCollecting watchdog>=2.1.5 (from streamlit->simpletransformers)\n  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (1.51.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (2.20.0)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (3.4.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (0.7.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (2.3.6)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (0.40.0)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (3.1.2)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (4.17.3)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (0.12.0)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb>=0.10.32->simpletransformers) (1.16.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (1.3.1)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (4.0.10)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->simpletransformers) (1.3.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7,>=1.4->streamlit->simpletransformers) (3.15.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.31.0->simpletransformers) (3.0.9)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (2.2.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (2.15.1)\nCollecting pytz-deprecation-shim (from tzlocal<5,>=1.1->streamlit->simpletransformers)\n  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->simpletransformers) (2.1.3)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (5.0.0)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.19.3)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->simpletransformers) (0.1.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->simpletransformers) (3.2.2)\nRequirement already satisfied: tzdata in /opt/conda/lib/python3.10/site-packages (from pytz-deprecation-shim->tzlocal<5,>=1.1->streamlit->simpletransformers) (2023.3)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=0cb8b2404c23250999ea5d48248f0f3bb3b93f0d701b8b51229f4dd109964911\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built seqeval\nInstalling collected packages: watchdog, validators, pytz-deprecation-shim, tzlocal, pydeck, transformers, seqeval, streamlit, simpletransformers\n  Attempting uninstall: tzlocal\n    Found existing installation: tzlocal 5.0.1\n    Uninstalling tzlocal-5.0.1:\n      Successfully uninstalled tzlocal-5.0.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.30.2\n    Uninstalling transformers-4.30.2:\n      Successfully uninstalled transformers-4.30.2\nSuccessfully installed pydeck-0.8.0 pytz-deprecation-shim-0.1.0.post0 seqeval-1.2.2 simpletransformers-0.64.3 streamlit-1.26.0 transformers-4.33.1 tzlocal-4.3.1 validators-0.22.0 watchdog-3.0.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Libraries & Functions","metadata":{}},{"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-09-15T15:27:48.184309Z","iopub.execute_input":"2023-09-15T15:27:48.184632Z","iopub.status.idle":"2023-09-15T15:27:48.189731Z","shell.execute_reply.started":"2023-09-15T15:27:48.184604Z","shell.execute_reply":"2023-09-15T15:27:48.188746Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from simpletransformers.classification import ClassificationModel\nimport torch","metadata":{"execution":{"iopub.status.busy":"2023-09-15T15:27:48.191064Z","iopub.execute_input":"2023-09-15T15:27:48.191982Z","iopub.status.idle":"2023-09-15T15:28:05.970295Z","shell.execute_reply.started":"2023-09-15T15:27:48.191947Z","shell.execute_reply":"2023-09-15T15:28:05.969298Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.preprocessing import LabelEncoder\n\ndef calculate_scores(y_test, y_pred, average = \"binary\"):\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred, average = average)\n    recall = recall_score(y_test, y_pred, average = average)\n    f1 = f1_score(y_test, y_pred, average = average)\n    return [accuracy, precision, recall, f1]","metadata":{"execution":{"iopub.status.busy":"2023-09-15T15:28:05.972965Z","iopub.execute_input":"2023-09-15T15:28:05.973865Z","iopub.status.idle":"2023-09-15T15:28:05.997734Z","shell.execute_reply.started":"2023-09-15T15:28:05.973828Z","shell.execute_reply":"2023-09-15T15:28:05.996668Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"model_names = [\"distilbert\", \"distilbert\", \"debertav2\", \"electra\"]\ncheckpoint_names = [\"ViktorDo/EcoBERT-Pretrained\", \"distilbert-base-uncased\", \"microsoft/deberta-v3-base\", \"google/electra-base-discriminator\"]","metadata":{"execution":{"iopub.status.busy":"2023-09-15T15:28:05.998988Z","iopub.execute_input":"2023-09-15T15:28:05.999405Z","iopub.status.idle":"2023-09-15T15:28:06.004734Z","shell.execute_reply.started":"2023-09-15T15:28:05.999369Z","shell.execute_reply":"2023-09-15T15:28:06.003806Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Input Data","metadata":{}},{"cell_type":"code","source":"raw_datasets = dict()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T15:28:06.006591Z","iopub.execute_input":"2023-09-15T15:28:06.006966Z","iopub.status.idle":"2023-09-15T15:28:06.016212Z","shell.execute_reply.started":"2023-09-15T15:28:06.006929Z","shell.execute_reply":"2023-09-15T15:28:06.015143Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"description_threshold = 100","metadata":{"execution":{"iopub.status.busy":"2023-09-15T15:28:06.017683Z","iopub.execute_input":"2023-09-15T15:28:06.017945Z","iopub.status.idle":"2023-09-15T15:28:06.027334Z","shell.execute_reply.started":"2023-09-15T15:28:06.017921Z","shell.execute_reply":"2023-09-15T15:28:06.026313Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## POWO Dataset","metadata":{}},{"cell_type":"code","source":"working_dir = \"..//input//powo-family//\" \n\ndf_POWO_Fam =  pd.read_excel(working_dir + \"POWO_Family.xlsx\")\ndf_POWO_Fam_Preproc = df_POWO_Fam.drop_duplicates(subset = [\"BERT_description\"])\ndf_POWO_Fam_Preproc = df_POWO_Fam_Preproc[df_POWO_Fam_Preproc[\"BERT_description\"].apply(lambda x: len(x.split(\" \")))>10]\n\nPOWO_Filter = df_POWO_Fam_Preproc[\"family\"].value_counts().keys().values[:10]\ndf_POWO_Fam_Preproc = df_POWO_Fam_Preproc[df_POWO_Fam_Preproc[\"family\"].apply(lambda x: x in POWO_Filter)].groupby('family', group_keys=False).apply(lambda x: x.sample(500, random_state = 42))\nraw_datasets[\"POWO\"] = df_POWO_Fam_Preproc","metadata":{"execution":{"iopub.status.busy":"2023-09-15T15:28:06.028607Z","iopub.execute_input":"2023-09-15T15:28:06.029155Z","iopub.status.idle":"2023-09-15T15:28:26.189486Z","shell.execute_reply.started":"2023-09-15T15:28:06.029119Z","shell.execute_reply":"2023-09-15T15:28:26.187936Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## WIKI Dataset","metadata":{}},{"cell_type":"code","source":"def fix_WIKI(name, description):\n    for n in name.split(\" \"):\n        description = str(description).replace(n.lower(), \"\")\n    return description.strip()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T15:28:26.191458Z","iopub.execute_input":"2023-09-15T15:28:26.192201Z","iopub.status.idle":"2023-09-15T15:28:26.201004Z","shell.execute_reply.started":"2023-09-15T15:28:26.192165Z","shell.execute_reply":"2023-09-15T15:28:26.198038Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"working_dir = \"..//input//wiki-family//\" \n\ndf_WIKI_Fam =  pd.read_excel(working_dir + \"WIKI_Family.xlsx\")\ndf_WIKI_Fam_Preproc = df_WIKI_Fam.drop_duplicates(subset = [\"BERT_description\"])\ndf_WIKI_Fam_Preproc[\"BERT_description\"] = df_WIKI_Fam_Preproc[[\"name\", \"BERT_description\"]].apply(lambda x: fix_WIKI(x[0], x[1]), axis = 1)\ndf_WIKI_Fam_Preproc = df_WIKI_Fam_Preproc[df_WIKI_Fam_Preproc[\"BERT_description\"].apply(lambda x: len(str(x).split(\" \")))>10]\n\nWIKI_Filter = df_WIKI_Fam_Preproc[\"family\"].value_counts().keys().values[:10]\ndf_WIKI_Fam_Preproc = df_WIKI_Fam_Preproc[df_WIKI_Fam_Preproc[\"family\"].apply(lambda x: x in WIKI_Filter)].groupby('family', group_keys=False).apply(lambda x: x.sample(500, random_state = 42))\nraw_datasets[\"WIKI\"] = df_WIKI_Fam_Preproc","metadata":{"execution":{"iopub.status.busy":"2023-09-15T15:28:26.205561Z","iopub.execute_input":"2023-09-15T15:28:26.205956Z","iopub.status.idle":"2023-09-15T15:28:51.576649Z","shell.execute_reply.started":"2023-09-15T15:28:26.205919Z","shell.execute_reply":"2023-09-15T15:28:51.575662Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_29/1233968646.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_WIKI_Fam_Preproc[\"BERT_description\"] = df_WIKI_Fam_Preproc[[\"name\", \"BERT_description\"]].apply(lambda x: fix_WIKI(x[0], x[1]), axis = 1)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Preprocess Datasets","metadata":{}},{"cell_type":"code","source":"preprocessed_dataset_dict = {}\nfor dataset_name in list(raw_datasets.keys()):\n    labelencoder = LabelEncoder()\n    raw_datasets[dataset_name][\"family_encoded\"] = labelencoder.fit_transform(raw_datasets[dataset_name][\"family\"])\n\n    indices_train, indices_test \\\n        = train_test_split(raw_datasets[dataset_name].index.values, test_size=0.25, random_state=42)\n    \n    \n    df_train = raw_datasets[dataset_name].loc[indices_train, [\"BERT_description\", \"family_encoded\"]]\n    df_train.columns = [\"text\", \"labels\"]\n    df_test = raw_datasets[dataset_name].loc[indices_test, [\"BERT_description\", \"family_encoded\"]]\n    df_test.columns = [\"text\", \"labels\"]\n\n    preprocessed_dataset_dict[dataset_name, \"train\"] = df_train\n    preprocessed_dataset_dict[dataset_name, \"validation\"] = df_test","metadata":{"execution":{"iopub.status.busy":"2023-09-15T15:28:51.578549Z","iopub.execute_input":"2023-09-15T15:28:51.578897Z","iopub.status.idle":"2023-09-15T15:28:51.602218Z","shell.execute_reply.started":"2023-09-15T15:28:51.578865Z","shell.execute_reply":"2023-09-15T15:28:51.601123Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Model Training & Evaluation","metadata":{"execution":{"iopub.status.busy":"2023-08-31T09:45:41.642737Z","iopub.execute_input":"2023-08-31T09:45:41.643140Z","iopub.status.idle":"2023-08-31T09:45:41.648018Z","shell.execute_reply.started":"2023-08-31T09:45:41.643109Z","shell.execute_reply":"2023-08-31T09:45:41.647123Z"}}},{"cell_type":"code","source":"if torch.cuda.is_available():  # Tell PyTorch to use the GPU. \n    device = torch.device(\"cuda\") \n    print('There are %d GPU(s) available.' % torch.cuda.device_count()) \n    print('We will use the GPU:', torch.cuda.get_device_name(0)) # If not...\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")\n    \nimport gc\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T15:28:51.603910Z","iopub.execute_input":"2023-09-15T15:28:51.604551Z","iopub.status.idle":"2023-09-15T15:28:52.025475Z","shell.execute_reply.started":"2023-09-15T15:28:51.604516Z","shell.execute_reply":"2023-09-15T15:28:52.024560Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"There are 2 GPU(s) available.\nWe will use the GPU: Tesla T4\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"130"},"metadata":{}}]},{"cell_type":"code","source":"results_list = []\n\nfor model_name, model_checkpoint in zip(model_names[:], checkpoint_names[:]):\n    for dataset_name in list(raw_datasets.keys())[:]:\n\n        print(model_checkpoint, dataset_name)\n        \n        if(model_checkpoint == \"ViktorDo/EcoBERT-Pretrained\"):\n            model = ClassificationModel(\n                model_name,\n                model_checkpoint,\n                tokenizer_name = \"distilbert-base-uncased\",\n                num_labels = 10, #preprocessed_dataset_dict[dataset_name, \"train\"][\"labels\"].nunique(),\n                args = {\"num_train_epochs\": 3, \"train_batch_size\":8, \"eval_batch_size\":8, \"reprocess_input_data\": True, \"overwrite_output_dir\": True, \"save_model_every_epoch\": False, \"save_eval_checkpoints\": False, \"max_seq_length\": 512}, #\"weight_decay\": 0.01, \"learning_rate\": 2e-5, \n            )\n        else:\n            model = ClassificationModel(\n                model_name,\n                model_checkpoint,\n                num_labels = 10, #preprocessed_dataset_dict[dataset_name, \"train\"][\"labels\"].nunique(),\n                args = {\"num_train_epochs\": 3, \"train_batch_size\":8, \"eval_batch_size\":8, \"reprocess_input_data\": True, \"overwrite_output_dir\": True, \"save_model_every_epoch\": False, \"save_eval_checkpoints\": False, \"max_seq_length\": 512}, #\"weight_decay\": 0.01, \"learning_rate\": 2e-5, \n            )\n        # Train the model\n        model.train_model(preprocessed_dataset_dict[dataset_name, \"train\"])\n\n        # Evaluate the model\n        result, model_outputs, wrong_predictions = model.eval_model(preprocessed_dataset_dict[dataset_name, \"validation\"])\n        preprocessed_dataset_dict[dataset_name, \"validation\"][\"prediction\"] = np.argmax(model_outputs, axis=1)\n        results = calculate_scores(preprocessed_dataset_dict[dataset_name, \"validation\"][\"labels\"], preprocessed_dataset_dict[dataset_name, \"validation\"][\"prediction\"], average = \"macro\")\n        results_list.append([dataset_name, \"Family\"] + results + [model_name])\n\n        torch.cuda.empty_cache()\n        gc.collect()\n\n\ndf_results = pd.DataFrame(results_list, columns=[\"Dataset\", \"Trait\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"Model\"])","metadata":{"execution":{"iopub.status.busy":"2023-09-15T15:28:52.027961Z","iopub.execute_input":"2023-09-15T15:28:52.028325Z","iopub.status.idle":"2023-09-15T16:30:09.523275Z","shell.execute_reply.started":"2023-09-15T15:28:52.028291Z","shell.execute_reply":"2023-09-15T16:30:09.522148Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"ViktorDo/EcoBERT-Pretrained POWO\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/552 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7b2904867714958a07d36b435439524"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6abf35d84ae34dc19f1466c2c4943f76"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at ViktorDo/EcoBERT-Pretrained and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8202594ad3204536bedab7174a3af5e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e86820469d2649dd8b4fb07bada9ab10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53aa6fdb00e54fccb1f1e1445da296ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a27f7313b4a4600819b1fa6c220738f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3026ff96ff514464b586331bb957ace7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a06adcab451048eca660b71b5857ce78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 3:   0%|          | 0/469 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5b5bec2bf834436ade3fc383f00b678"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 3:   0%|          | 0/469 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"495192685d984357bafd776df4b647d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 3:   0%|          | 0/469 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24219231d46648908ff6d11b6ad2abf9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d10dcb409c52412fbed8d5ae38992e5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef06e88279db41d78c38db2f3f11e333"}},"metadata":{}},{"name":"stdout","text":"ViktorDo/EcoBERT-Pretrained WIKI\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at ViktorDo/EcoBERT-Pretrained and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18e840da400a43c38fba5186bc47b805"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4fdb008964c4877a00dff06ce5dddd0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 3:   0%|          | 0/469 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5c773e3c5c74ab1b3e1165aeb59c3de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 3:   0%|          | 0/469 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d74ce20fb2d94a7a88a5beb90e998f3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 3:   0%|          | 0/469 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d576b2836ba041e2b46a96a4dc3c31f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c48ea06abadb446b85d1e0ac15907d75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2e09e4762ab42f8aabc9326fda8a85c"}},"metadata":{}},{"name":"stdout","text":"distilbert-base-uncased POWO\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fbcfe607b4a44dcb4b727ce5a35f1f9"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e901ff7df2cd4669b0a3054dc83d3799"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9bc478e9e554e2c9acc81e4eedb644f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 3:   0%|          | 0/469 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"997d344ae1f24304b4fab6baaac82e85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 3:   0%|          | 0/469 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b42a1bb2f04146099423535c974f9038"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 3:   0%|          | 0/469 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33857c28d0584502ad260498dfebeb57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"915464f9db444a9bbe5c7fcac0ec602d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"987cd21cc7834f3c9bf91c850573bf92"}},"metadata":{}},{"name":"stdout","text":"distilbert-base-uncased WIKI\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea701378b17e4543bf69bc20b889de56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3d0f5babaec45e5ac8775b243895432"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 3:   0%|          | 0/469 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7dec63fb07cc4d76b79b4cfd5bd1e618"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 3:   0%|          | 0/469 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cb66a62660d4763b711d24ffb3f8e76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 3:   0%|          | 0/469 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"072c6fb7107e486583b25fd7a685ad5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6f282eb6bec4167a208287b9ee8eb59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f29ab4911016419db212ec082d6f79c1"}},"metadata":{}},{"name":"stdout","text":"microsoft/deberta-v3-base POWO\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36ba605049784427a7133cebab372144"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a913992fa70944e89738f47fef05bb6e"}},"metadata":{}},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'pooler.dense.weight', 'classifier.weight', 'pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4da5b77fdf8245d0a5ebeb08d902ffd7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0229cda0ec544ddc8078fb3725a6db07"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc4dffaf56764ae0a1538b2c005fc115"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2854d958fb134bb5a8fe55a642480cc6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 3:   0%|          | 0/469 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd83b14f3b1b484d840741546ec15d03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 3:   0%|          | 0/469 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d44435bfecc043aca7b316c5d13afea2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 3:   0%|          | 0/469 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04e16f310657474483b6c496651340e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a64be04d605e42b2b7027c0e8d4ec23a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8eefad6096e149279fe0c4f2dcbc0a12"}},"metadata":{}},{"name":"stdout","text":"microsoft/deberta-v3-base WIKI\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'pooler.dense.weight', 'classifier.weight', 'pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b925e0a899e1433299ef7d2bba3ec601"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6d98cca49ab455f88dfa2e38e8c593d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 3:   0%|          | 0/469 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a0ecf79af5145fab2920fce3ebcc6d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 3:   0%|          | 0/469 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"360408c2afcc4270a919184ba84d4363"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 3:   0%|          | 0/469 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6627863627f4aadb2dd862a05611f38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7864cee425d472eb6c2a48dd5bfbe9d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9323e67ae4d54c38ad384bbb7d5d4c57"}},"metadata":{}},{"name":"stdout","text":"google/electra-base-discriminator POWO\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a31982f10a546d5b6183a22b96d3ffb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"275cf7804c464904b2713c20e22145a6"}},"metadata":{}},{"name":"stderr","text":"Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/27.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc406fe2cfd746cdbd9c93a71902833f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30eb3f96b6934424be0fc7685b5067ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0ae1355986f476eaa46b993910c0e8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eadc3c8664504c358af4a3693368e158"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"441fa193c5434c559d2245de94f4ae7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 3:   0%|          | 0/469 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37eb2ee3442941a889f227f0845d470b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 3:   0%|          | 0/469 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"993fff8ebc824a01acd1236420b8911e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 3:   0%|          | 0/469 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c98eceeb19454d64bff161da9df13551"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65bb9f7e2b4d45f9acfaa4a437ab9631"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cf6082d40284377b8cb30bcf9c4568a"}},"metadata":{}},{"name":"stdout","text":"google/electra-base-discriminator WIKI\n","output_type":"stream"},{"name":"stderr","text":"Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbcbca3b1004432b833f1862563c4f48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da2f037afd0d402d8ead3463576b0b72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 3:   0%|          | 0/469 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9c7be8c069e43f090f23ebbd70f6ac1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 3:   0%|          | 0/469 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"909e0046bb47467aba409fb0bc4eacc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 3:   0%|          | 0/469 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7737a4e27c0a4ff584cbdaaae7d8ce36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0712a5a099a240be9a6dafda29adb038"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd56a13fc1a24781bc6ac350c01f1983"}},"metadata":{}}]},{"cell_type":"code","source":"df_results = pd.DataFrame(results_list, columns=[\"Dataset\", \"Trait\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"Model\"])","metadata":{"execution":{"iopub.status.busy":"2023-09-15T16:30:09.525026Z","iopub.execute_input":"2023-09-15T16:30:09.525396Z","iopub.status.idle":"2023-09-15T16:30:09.532364Z","shell.execute_reply.started":"2023-09-15T16:30:09.525368Z","shell.execute_reply":"2023-09-15T16:30:09.531465Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"df_results","metadata":{"execution":{"iopub.status.busy":"2023-09-15T16:30:09.533911Z","iopub.execute_input":"2023-09-15T16:30:09.534967Z","iopub.status.idle":"2023-09-15T16:30:09.563360Z","shell.execute_reply.started":"2023-09-15T16:30:09.534932Z","shell.execute_reply":"2023-09-15T16:30:09.562374Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"  Dataset   Trait  Accuracy  Precision    Recall  F1-Score       Model\n0    POWO  Family    0.9648   0.965422  0.965381  0.965209  distilbert\n1    WIKI  Family    0.9712   0.970690  0.970147  0.970250  distilbert\n2    POWO  Family    0.9680   0.968400  0.968147  0.968233  distilbert\n3    WIKI  Family    0.9712   0.970701  0.970070  0.970276  distilbert\n4    POWO  Family    0.9480   0.949728  0.948704  0.948944   debertav2\n5    WIKI  Family    0.9656   0.965516  0.964464  0.964734   debertav2\n6    POWO  Family    0.9640   0.965100  0.964041  0.964369     electra\n7    WIKI  Family    0.9712   0.970611  0.970563  0.970299     electra","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataset</th>\n      <th>Trait</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1-Score</th>\n      <th>Model</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>POWO</td>\n      <td>Family</td>\n      <td>0.9648</td>\n      <td>0.965422</td>\n      <td>0.965381</td>\n      <td>0.965209</td>\n      <td>distilbert</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>WIKI</td>\n      <td>Family</td>\n      <td>0.9712</td>\n      <td>0.970690</td>\n      <td>0.970147</td>\n      <td>0.970250</td>\n      <td>distilbert</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>POWO</td>\n      <td>Family</td>\n      <td>0.9680</td>\n      <td>0.968400</td>\n      <td>0.968147</td>\n      <td>0.968233</td>\n      <td>distilbert</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>WIKI</td>\n      <td>Family</td>\n      <td>0.9712</td>\n      <td>0.970701</td>\n      <td>0.970070</td>\n      <td>0.970276</td>\n      <td>distilbert</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>POWO</td>\n      <td>Family</td>\n      <td>0.9480</td>\n      <td>0.949728</td>\n      <td>0.948704</td>\n      <td>0.948944</td>\n      <td>debertav2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>WIKI</td>\n      <td>Family</td>\n      <td>0.9656</td>\n      <td>0.965516</td>\n      <td>0.964464</td>\n      <td>0.964734</td>\n      <td>debertav2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>POWO</td>\n      <td>Family</td>\n      <td>0.9640</td>\n      <td>0.965100</td>\n      <td>0.964041</td>\n      <td>0.964369</td>\n      <td>electra</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>WIKI</td>\n      <td>Family</td>\n      <td>0.9712</td>\n      <td>0.970611</td>\n      <td>0.970563</td>\n      <td>0.970299</td>\n      <td>electra</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_results.to_excel(\"FamilyClassification_Encoder_Results.xlsx\", index = False)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T16:30:09.564656Z","iopub.execute_input":"2023-09-15T16:30:09.564995Z","iopub.status.idle":"2023-09-15T16:30:09.597301Z","shell.execute_reply.started":"2023-09-15T16:30:09.564960Z","shell.execute_reply":"2023-09-15T16:30:09.596463Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"df_results","metadata":{"execution":{"iopub.status.busy":"2023-09-15T16:30:09.600262Z","iopub.execute_input":"2023-09-15T16:30:09.600537Z","iopub.status.idle":"2023-09-15T16:30:09.618273Z","shell.execute_reply.started":"2023-09-15T16:30:09.600513Z","shell.execute_reply":"2023-09-15T16:30:09.617202Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"  Dataset   Trait  Accuracy  Precision    Recall  F1-Score       Model\n0    POWO  Family    0.9648   0.965422  0.965381  0.965209  distilbert\n1    WIKI  Family    0.9712   0.970690  0.970147  0.970250  distilbert\n2    POWO  Family    0.9680   0.968400  0.968147  0.968233  distilbert\n3    WIKI  Family    0.9712   0.970701  0.970070  0.970276  distilbert\n4    POWO  Family    0.9480   0.949728  0.948704  0.948944   debertav2\n5    WIKI  Family    0.9656   0.965516  0.964464  0.964734   debertav2\n6    POWO  Family    0.9640   0.965100  0.964041  0.964369     electra\n7    WIKI  Family    0.9712   0.970611  0.970563  0.970299     electra","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataset</th>\n      <th>Trait</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1-Score</th>\n      <th>Model</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>POWO</td>\n      <td>Family</td>\n      <td>0.9648</td>\n      <td>0.965422</td>\n      <td>0.965381</td>\n      <td>0.965209</td>\n      <td>distilbert</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>WIKI</td>\n      <td>Family</td>\n      <td>0.9712</td>\n      <td>0.970690</td>\n      <td>0.970147</td>\n      <td>0.970250</td>\n      <td>distilbert</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>POWO</td>\n      <td>Family</td>\n      <td>0.9680</td>\n      <td>0.968400</td>\n      <td>0.968147</td>\n      <td>0.968233</td>\n      <td>distilbert</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>WIKI</td>\n      <td>Family</td>\n      <td>0.9712</td>\n      <td>0.970701</td>\n      <td>0.970070</td>\n      <td>0.970276</td>\n      <td>distilbert</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>POWO</td>\n      <td>Family</td>\n      <td>0.9480</td>\n      <td>0.949728</td>\n      <td>0.948704</td>\n      <td>0.948944</td>\n      <td>debertav2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>WIKI</td>\n      <td>Family</td>\n      <td>0.9656</td>\n      <td>0.965516</td>\n      <td>0.964464</td>\n      <td>0.964734</td>\n      <td>debertav2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>POWO</td>\n      <td>Family</td>\n      <td>0.9640</td>\n      <td>0.965100</td>\n      <td>0.964041</td>\n      <td>0.964369</td>\n      <td>electra</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>WIKI</td>\n      <td>Family</td>\n      <td>0.9712</td>\n      <td>0.970611</td>\n      <td>0.970563</td>\n      <td>0.970299</td>\n      <td>electra</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}