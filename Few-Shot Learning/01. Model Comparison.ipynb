{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install simpletransformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-24T18:29:02.361688Z","iopub.execute_input":"2023-09-24T18:29:02.362535Z","iopub.status.idle":"2023-09-24T18:29:27.058939Z","shell.execute_reply.started":"2023-09-24T18:29:02.362500Z","shell.execute_reply":"2023-09-24T18:29:27.057836Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting simpletransformers\n  Downloading simpletransformers-0.64.3-py3-none-any.whl (250 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.8/250.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (1.23.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (2.31.0)\nRequirement already satisfied: tqdm>=4.47.0 in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (4.66.1)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (2023.6.3)\nRequirement already satisfied: transformers>=4.31.0 in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (4.32.1)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (2.1.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (1.11.2)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (1.2.2)\nCollecting seqeval (from simpletransformers)\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (2.12.3)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (2.0.2)\nRequirement already satisfied: tokenizers in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (0.13.3)\nRequirement already satisfied: wandb>=0.10.32 in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (0.15.9)\nCollecting streamlit (from simpletransformers)\n  Downloading streamlit-1.27.0-py2.py3-none-any.whl (7.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (0.1.99)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (0.16.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (6.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (0.3.3)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (3.1.31)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (1.30.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (0.4.0)\nRequirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (0.1.2)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (1.3.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (68.0.0)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (3.20.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->simpletransformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->simpletransformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->simpletransformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->simpletransformers) (2023.7.22)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (0.3.7)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (3.3.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (2023.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (3.8.4)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (0.18.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->simpletransformers) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->simpletransformers) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->simpletransformers) (2023.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->simpletransformers) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->simpletransformers) (3.1.0)\nRequirement already satisfied: altair<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (5.1.0)\nRequirement already satisfied: blinker<2,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (1.6.2)\nRequirement already satisfied: cachetools<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (4.2.4)\nRequirement already satisfied: importlib-metadata<7,>=1.4 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (6.7.0)\nRequirement already satisfied: pillow<10,>=7.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (9.5.0)\nRequirement already satisfied: rich<14,>=10.14.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (13.4.2)\nRequirement already satisfied: tenacity<9,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (8.2.2)\nRequirement already satisfied: toml<2,>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (0.10.2)\nRequirement already satisfied: typing-extensions<5,>=4.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (4.6.3)\nRequirement already satisfied: tzlocal<6,>=1.1 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (5.0.1)\nCollecting validators<1,>=0.2 (from streamlit->simpletransformers)\n  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\nCollecting pydeck<1,>=0.8.0b4 (from streamlit->simpletransformers)\n  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (6.3.2)\nCollecting watchdog>=2.1.5 (from streamlit->simpletransformers)\n  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (1.51.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (2.20.0)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (3.4.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (0.7.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (2.3.7)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (0.40.0)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (3.1.2)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (4.17.3)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (0.12.0)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb>=0.10.32->simpletransformers) (1.16.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (1.3.1)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (4.0.10)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->simpletransformers) (1.3.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7,>=1.4->streamlit->simpletransformers) (3.15.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.31.0->simpletransformers) (3.0.9)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (2.2.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (2.15.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->simpletransformers) (2.1.3)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (5.0.0)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.19.3)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->simpletransformers) (0.1.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->simpletransformers) (3.2.2)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16165 sha256=09c9eb9182e92b6ff7f87f19a42dd22e6f31f3471210b886d0c6e10372171308\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built seqeval\nInstalling collected packages: watchdog, validators, pydeck, seqeval, streamlit, simpletransformers\nSuccessfully installed pydeck-0.8.1b0 seqeval-1.2.2 simpletransformers-0.64.3 streamlit-1.27.0 validators-0.22.0 watchdog-3.0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install datasets\n!pip install sentence_transformers\n!pip install setfit","metadata":{"execution":{"iopub.status.busy":"2023-09-24T18:29:27.061969Z","iopub.execute_input":"2023-09-24T18:29:27.062361Z","iopub.status.idle":"2023-09-24T18:30:07.584536Z","shell.execute_reply.started":"2023-09-24T18:29:27.062327Z","shell.execute_reply":"2023-09-24T18:30:07.583395Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.3.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nCollecting sentence_transformers\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.32.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.66.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.15.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.23.5)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.11.2)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.1.99)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.16.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.6.3)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.6.3)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.3.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence_transformers) (1.16.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.1.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence_transformers) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\nBuilding wheels for collected packages: sentence_transformers\n  Building wheel for sentence_transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=1ad06a6cd0f289a405fd4ba3980b98ca0e223ac945b8f05631075200da0d2bd4\n  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\nSuccessfully built sentence_transformers\nInstalling collected packages: sentence_transformers\nSuccessfully installed sentence_transformers-2.2.2\nCollecting setfit\n  Downloading setfit-0.7.0-py3-none-any.whl (45 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting datasets>=2.3.0 (from setfit)\n  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: sentence-transformers>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from setfit) (2.2.2)\nCollecting evaluate>=0.3.0 (from setfit)\n  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.3.0->setfit) (1.23.5)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.3.0->setfit) (11.0.0)\nRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.3.0->setfit) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets>=2.3.0->setfit) (2.0.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.3.0->setfit) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.3.0->setfit) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=2.3.0->setfit) (3.3.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=2.3.0->setfit) (0.70.15)\nRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.3.0->setfit) (2023.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.3.0->setfit) (3.8.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.3.0->setfit) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets>=2.3.0->setfit) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.3.0->setfit) (6.0)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate>=0.3.0->setfit) (0.18.0)\nRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.2.1->setfit) (4.32.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.2.1->setfit) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.2.1->setfit) (0.15.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.2.1->setfit) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.2.1->setfit) (1.11.2)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.2.1->setfit) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.2.1->setfit) (0.1.99)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.3.0->setfit) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.3.0->setfit) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.3.0->setfit) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.3.0->setfit) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.3.0->setfit) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.3.0->setfit) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.3.0->setfit) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets>=2.3.0->setfit) (3.12.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets>=2.3.0->setfit) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets>=2.3.0->setfit) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.3.0->setfit) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.3.0->setfit) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.3.0->setfit) (2023.7.22)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers>=2.2.1->setfit) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers>=2.2.1->setfit) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers>=2.2.1->setfit) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.1->setfit) (2023.6.3)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.1->setfit) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.1->setfit) (0.3.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers>=2.2.1->setfit) (1.16.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.3.0->setfit) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.3.0->setfit) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.3.0->setfit) (2023.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.2.1->setfit) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.2.1->setfit) (3.1.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers>=2.2.1->setfit) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers>=2.2.1->setfit) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers>=2.2.1->setfit) (1.3.0)\nInstalling collected packages: datasets, evaluate, setfit\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.1.0\n    Uninstalling datasets-2.1.0:\n      Successfully uninstalled datasets-2.1.0\nSuccessfully installed datasets-2.14.5 evaluate-0.4.0 setfit-0.7.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Libraries & Functions","metadata":{}},{"cell_type":"code","source":"from datasets import Dataset\nfrom sentence_transformers.losses import CosineSimilarityLoss\nfrom setfit import SetFitModel, SetFitTrainer, sample_dataset","metadata":{"execution":{"iopub.status.busy":"2023-09-24T18:30:07.586555Z","iopub.execute_input":"2023-09-24T18:30:07.586914Z","iopub.status.idle":"2023-09-24T18:30:23.233334Z","shell.execute_reply.started":"2023-09-24T18:30:07.586882Z","shell.execute_reply":"2023-09-24T18:30:23.232371Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-09-24T18:30:23.236041Z","iopub.execute_input":"2023-09-24T18:30:23.236437Z","iopub.status.idle":"2023-09-24T18:30:23.240910Z","shell.execute_reply.started":"2023-09-24T18:30:23.236405Z","shell.execute_reply":"2023-09-24T18:30:23.240028Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from simpletransformers.classification import ClassificationModel\nimport torch","metadata":{"execution":{"iopub.status.busy":"2023-09-24T18:30:23.242364Z","iopub.execute_input":"2023-09-24T18:30:23.242980Z","iopub.status.idle":"2023-09-24T18:30:24.140625Z","shell.execute_reply.started":"2023-09-24T18:30:23.242944Z","shell.execute_reply":"2023-09-24T18:30:24.139644Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.preprocessing import LabelEncoder\n\ndef calculate_scores(y_test, y_pred, average = \"binary\"):\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred, average = average)\n    recall = recall_score(y_test, y_pred, average = average)\n    f1 = f1_score(y_test, y_pred, average = average)\n    return [accuracy, precision, recall, f1]","metadata":{"execution":{"iopub.status.busy":"2023-09-24T18:30:24.142090Z","iopub.execute_input":"2023-09-24T18:30:24.142450Z","iopub.status.idle":"2023-09-24T18:30:24.152007Z","shell.execute_reply.started":"2023-09-24T18:30:24.142413Z","shell.execute_reply":"2023-09-24T18:30:24.151042Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model_names = [\"distilbert\"]\ncheckpoint_names = [\"distilbert-base-uncased\"]","metadata":{"execution":{"iopub.status.busy":"2023-09-24T18:30:24.155519Z","iopub.execute_input":"2023-09-24T18:30:24.155801Z","iopub.status.idle":"2023-09-24T18:30:24.160794Z","shell.execute_reply.started":"2023-09-24T18:30:24.155777Z","shell.execute_reply":"2023-09-24T18:30:24.159881Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"focus_names = [\"Growth Form\"]#, \"Life Form\"]\nfocus_codes = [\"1.2.1\"]#, \"2.3.1\"]","metadata":{"execution":{"iopub.status.busy":"2023-09-24T18:30:24.162661Z","iopub.execute_input":"2023-09-24T18:30:24.163386Z","iopub.status.idle":"2023-09-24T18:30:24.170569Z","shell.execute_reply.started":"2023-09-24T18:30:24.163354Z","shell.execute_reply":"2023-09-24T18:30:24.169641Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Input Data","metadata":{}},{"cell_type":"code","source":"raw_datasets = dict()","metadata":{"execution":{"iopub.status.busy":"2023-09-24T18:30:24.173787Z","iopub.execute_input":"2023-09-24T18:30:24.174074Z","iopub.status.idle":"2023-09-24T18:30:24.181114Z","shell.execute_reply.started":"2023-09-24T18:30:24.174044Z","shell.execute_reply":"2023-09-24T18:30:24.180032Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## POWO Dataset","metadata":{}},{"cell_type":"code","source":"working_dir = \"..//input//powo-gift-final//\" \n\ndf_POWO_Cat =  pd.read_excel(working_dir + \"POWO_GIFT_Final.xlsx\")\ndf_POWO_Cat_Preproc = df_POWO_Cat.drop_duplicates(subset = [\"BERT_description\"])\ndf_POWO_Cat_Preproc = df_POWO_Cat_Preproc[df_POWO_Cat_Preproc[\"BERT_description\"].apply(lambda x: len(x.split(\" \")))>10]\nraw_datasets[\"POWO\"] = df_POWO_Cat_Preproc","metadata":{"execution":{"iopub.status.busy":"2023-09-24T18:30:24.185312Z","iopub.execute_input":"2023-09-24T18:30:24.185586Z","iopub.status.idle":"2023-09-24T18:31:07.639961Z","shell.execute_reply.started":"2023-09-24T18:30:24.185562Z","shell.execute_reply":"2023-09-24T18:31:07.638933Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## WIKI Dataset","metadata":{}},{"cell_type":"code","source":"def fix_WIKI(name, description):\n    for n in name.split(\" \"):\n        description = str(description).replace(n.lower(), \"\")\n    return description.strip()","metadata":{"execution":{"iopub.status.busy":"2023-09-24T18:31:07.641381Z","iopub.execute_input":"2023-09-24T18:31:07.667595Z","iopub.status.idle":"2023-09-24T18:31:07.673372Z","shell.execute_reply.started":"2023-09-24T18:31:07.667543Z","shell.execute_reply":"2023-09-24T18:31:07.672357Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"working_dir = \"..//input//wiki-gift-final//\" \n\ndf_WIKI_Cat =  pd.read_excel(working_dir + \"WIKI_GIFT_Final.xlsx\")\ndf_WIKI_Cat_Preproc = df_WIKI_Cat.drop_duplicates(subset = [\"BERT_description\"])\ndf_WIKI_Cat_Preproc[\"BERT_description\"] = df_WIKI_Cat_Preproc[[\"name\", \"BERT_description\"]].apply(lambda x: fix_WIKI(x[0], x[1]), axis = 1)\ndf_WIKI_Cat_Preproc = df_WIKI_Cat_Preproc[df_WIKI_Cat_Preproc[\"BERT_description\"].apply(lambda x: len(str(x).split(\" \")))>10]\nraw_datasets[\"WIKI\"] = df_WIKI_Cat_Preproc","metadata":{"execution":{"iopub.status.busy":"2023-09-24T18:31:07.674921Z","iopub.execute_input":"2023-09-24T18:31:07.675569Z","iopub.status.idle":"2023-09-24T18:31:57.184649Z","shell.execute_reply.started":"2023-09-24T18:31:07.675534Z","shell.execute_reply":"2023-09-24T18:31:57.183682Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_28/3714705271.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_WIKI_Cat_Preproc[\"BERT_description\"] = df_WIKI_Cat_Preproc[[\"name\", \"BERT_description\"]].apply(lambda x: fix_WIKI(x[0], x[1]), axis = 1)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Preprocess Datasets","metadata":{}},{"cell_type":"code","source":"label_map = {\n    \"Growth Form\": {\"herb\": 0, \"shrub\": 1, \"tree\": 2},\n    \"Life Form\": {\"phanerophyte\": 0, \"chamaephyte\": 1, \"hemicryptophyte\": 2, \"cryptophyte\": 3, \"therophyte\": 4},\n}\n","metadata":{"execution":{"iopub.status.busy":"2023-09-24T18:31:57.186228Z","iopub.execute_input":"2023-09-24T18:31:57.186605Z","iopub.status.idle":"2023-09-24T18:31:57.192860Z","shell.execute_reply.started":"2023-09-24T18:31:57.186568Z","shell.execute_reply":"2023-09-24T18:31:57.191967Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"preprocessed_dataset_dict = {}\nsample_size = 5000\nfor focus_name, focus_code in zip(focus_names, focus_codes):\n    for dataset_name in list(raw_datasets.keys()):\n        labelencoder = LabelEncoder()\n\n        dataset_masked = raw_datasets[dataset_name][raw_datasets[dataset_name][focus_code].notna()]\n        dataset_masked = dataset_masked[dataset_masked[focus_code].apply(lambda x: x in label_map[focus_name].keys())].sample(sample_size)\n        dataset_masked[focus_code + \"_encoded\"] = labelencoder.fit_transform(dataset_masked[focus_code])\n\n        indices_train, indices_test \\\n            = train_test_split(dataset_masked.index.values, test_size=0.25, random_state=42)\n            \n        df_train = dataset_masked.loc[indices_train, [\"BERT_description\", focus_code + \"_encoded\"]]\n        df_train.columns = [\"text\", \"labels\"]\n        df_test = dataset_masked.loc[indices_test, [\"BERT_description\", focus_code + \"_encoded\"]]\n        df_test.columns = [\"text\", \"labels\"]\n        \n        preprocessed_dataset_dict[dataset_name, focus_name, \"train\"] = df_train\n        preprocessed_dataset_dict[dataset_name, focus_name, \"validation\"] = df_test","metadata":{"execution":{"iopub.status.busy":"2023-09-24T18:31:57.194629Z","iopub.execute_input":"2023-09-24T18:31:57.195663Z","iopub.status.idle":"2023-09-24T18:31:57.361949Z","shell.execute_reply.started":"2023-09-24T18:31:57.195636Z","shell.execute_reply":"2023-09-24T18:31:57.360975Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Model Training & Evaluation","metadata":{}},{"cell_type":"markdown","source":"## DistilBERT","metadata":{}},{"cell_type":"code","source":"if torch.cuda.is_available():  # Tell PyTorch to use the GPU. \n    device = torch.device(\"cuda\") \n    print('There are %d GPU(s) available.' % torch.cuda.device_count()) \n    print('We will use the GPU:', torch.cuda.get_device_name(0)) # If not...\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")\n    \nimport gc\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-09-24T18:16:36.432486Z","iopub.execute_input":"2023-09-24T18:16:36.433463Z","iopub.status.idle":"2023-09-24T18:16:36.826316Z","shell.execute_reply.started":"2023-09-24T18:16:36.433425Z","shell.execute_reply":"2023-09-24T18:16:36.825256Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"There are 1 GPU(s) available.\nWe will use the GPU: Tesla P100-PCIE-16GB\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"30"},"metadata":{}}]},{"cell_type":"code","source":"results_list = []\nFS_sample_sizes = [32, 128, 512]\nfor model_name, model_checkpoint in zip(model_names[:], checkpoint_names[:]):\n    for dataset_name in list(raw_datasets.keys())[:]:\n        for FS_sample_size in FS_sample_sizes:\n            print(model_name, dataset_name)\n\n            model = ClassificationModel(\n                model_name,\n                model_checkpoint,\n                num_labels = preprocessed_dataset_dict[dataset_name, focus_name, \"train\"][\"labels\"].nunique(),\n                args = {\"num_train_epochs\": 3, \"train_batch_size\":8, \"eval_batch_size\":8, \"reprocess_input_data\": True, \"overwrite_output_dir\": True, \"save_model_every_epoch\": False, \"save_eval_checkpoints\": False, \"max_seq_length\": 512}, #\"weight_decay\": 0.01, \"learning_rate\": 2e-5, \n            )\n            # Train the model\n            model.train_model(preprocessed_dataset_dict[dataset_name, focus_name, \"train\"].sample(FS_sample_size, random_state = 42))\n\n            # Evaluate the model\n            result, model_outputs, wrong_predictions = model.eval_model(preprocessed_dataset_dict[dataset_name, focus_name, \"validation\"])\n            preprocessed_dataset_dict[dataset_name, focus_name, \"validation\"][\"prediction\"] = np.argmax(model_outputs, axis=1)\n            results = calculate_scores(preprocessed_dataset_dict[dataset_name, focus_name, \"validation\"][\"labels\"], preprocessed_dataset_dict[dataset_name, focus_name, \"validation\"][\"prediction\"], average = \"macro\")\n            results_list.append([dataset_name, focus_name, FS_sample_size] + results + [model_checkpoint])\n\n            torch.cuda.empty_cache()\n            gc.collect()\n\n\ndf_results = pd.DataFrame(results_list, columns=[\"Dataset\", \"Trait\", \"Sample Size\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"Model\"])","metadata":{"execution":{"iopub.status.busy":"2023-09-24T18:16:41.567146Z","iopub.execute_input":"2023-09-24T18:16:41.567906Z","iopub.status.idle":"2023-09-24T18:20:17.961098Z","shell.execute_reply.started":"2023-09-24T18:16:41.567860Z","shell.execute_reply":"2023-09-24T18:20:17.960065Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"distilbert POWO\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/32 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6b3d4db47334da0b9467c895e98ff44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd5572dbf5c449fdbb37da20bc1d258d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 3:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dcb33fd736e4f9b8c8c8fce815d5f2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 3:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfe7dbbe197547b19ee5a6bf9421d962"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 3:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5c9aae142344f32b6ddbdc6b458e8ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d63f85db9c9345d591eda8faab9db5d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5a5364e568a4563abb107e24351f94d"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"distilbert POWO\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f54e5e0064084226af14d88fbdcb1925"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21f7eeaf69d5443081af4f6dc5285aaf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 3:   0%|          | 0/16 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5eeacbe39f6b4d5494bdec4e55ba84c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 3:   0%|          | 0/16 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08b6f1ae6f2c4db19019899c0b871dc9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 3:   0%|          | 0/16 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c2a8aafe7df45f09c75df5235f9a754"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f96bb59e88b44f88a4ebd2109da424af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37ac1fe8865941d7838496f0e3a8dcb1"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"distilbert POWO\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/512 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2dff4c9a46984d19a46a3f59c0634827"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f167d9e048fd46fa860ace224ff7b2e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 3:   0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"188e9db4cf8e46e4a97d19c3fdffb188"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 3:   0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"febcfa3620644fd494e541dd0e344016"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 3:   0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2a93e5802e04aa39229c5d1efaa1c24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1beb416223b64dd9a3e2afebb2be0217"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10918b66aec24ef3a7b475a7ce006d8e"}},"metadata":{}},{"name":"stdout","text":"distilbert WIKI\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/32 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d26b38b3e08d4844899784e046639fff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12febe0a8a874b2fbde0eaaaeb7094f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 3:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7eb4e81d066f486ebdb57e49c4980a7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 3:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3efe6c75e4504ae38dffb0970bca9dc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 3:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cfd83e0265e414e97b0b2143bac886b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3374372f777d4fd59505eb1e24a0e322"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62c9ce8460f840e9a656719a2f5a420d"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"distilbert WIKI\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fce9170bdc12428dbee8b59ad233ac61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"710ddc52ae9244ecab77aa25bd1bce51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 3:   0%|          | 0/16 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15135bd8a08d4f89863a3175b8818026"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 3:   0%|          | 0/16 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8a2dbf7086c401a8fb2ba4a6b19a0da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 3:   0%|          | 0/16 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"177096840fc14b25a47a55f2ea1f2fcc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9fa0264ae00443eb60b5f7d3410cb69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"714fa202247b40ebb16286d288cd5bec"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"distilbert WIKI\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/512 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"894801a36cac448c91bba4a7f6410e6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed41996030874cf49ce7727b33890a67"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 0 of 3:   0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"190dd4d17b8b4305ac2865e3aeaa2f2e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 3:   0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ed8bd4ed2b243c2b6ae2fc7a8d4640c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 3:   0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f15a5475171443bba8e673fb6cf98e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2637794737740e080acf669e07e510f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4710fece22e6424e81f319d43400fc58"}},"metadata":{}}]},{"cell_type":"code","source":"df_results","metadata":{"execution":{"iopub.status.busy":"2023-09-24T18:20:17.963310Z","iopub.execute_input":"2023-09-24T18:20:17.963764Z","iopub.status.idle":"2023-09-24T18:20:17.978895Z","shell.execute_reply.started":"2023-09-24T18:20:17.963729Z","shell.execute_reply":"2023-09-24T18:20:17.977861Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"  Dataset        Trait  Sample Size  Accuracy  Precision    Recall  F1-Score  \\\n0    POWO  Growth Form           32    0.7128   0.237600  0.333333  0.277440   \n1    POWO  Growth Form          128    0.7128   0.237600  0.333333  0.277440   \n2    POWO  Growth Form          512    0.8848   0.819866  0.782708  0.796845   \n3    WIKI  Growth Form           32    0.5224   0.174133  0.333333  0.228762   \n4    WIKI  Growth Form          128    0.5232   0.507606  0.334234  0.230679   \n5    WIKI  Growth Form          512    0.8736   0.865919  0.822443  0.838805   \n\n                     Model  \n0  distilbert-base-uncased  \n1  distilbert-base-uncased  \n2  distilbert-base-uncased  \n3  distilbert-base-uncased  \n4  distilbert-base-uncased  \n5  distilbert-base-uncased  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataset</th>\n      <th>Trait</th>\n      <th>Sample Size</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1-Score</th>\n      <th>Model</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>POWO</td>\n      <td>Growth Form</td>\n      <td>32</td>\n      <td>0.7128</td>\n      <td>0.237600</td>\n      <td>0.333333</td>\n      <td>0.277440</td>\n      <td>distilbert-base-uncased</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>POWO</td>\n      <td>Growth Form</td>\n      <td>128</td>\n      <td>0.7128</td>\n      <td>0.237600</td>\n      <td>0.333333</td>\n      <td>0.277440</td>\n      <td>distilbert-base-uncased</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>POWO</td>\n      <td>Growth Form</td>\n      <td>512</td>\n      <td>0.8848</td>\n      <td>0.819866</td>\n      <td>0.782708</td>\n      <td>0.796845</td>\n      <td>distilbert-base-uncased</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>WIKI</td>\n      <td>Growth Form</td>\n      <td>32</td>\n      <td>0.5224</td>\n      <td>0.174133</td>\n      <td>0.333333</td>\n      <td>0.228762</td>\n      <td>distilbert-base-uncased</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>WIKI</td>\n      <td>Growth Form</td>\n      <td>128</td>\n      <td>0.5232</td>\n      <td>0.507606</td>\n      <td>0.334234</td>\n      <td>0.230679</td>\n      <td>distilbert-base-uncased</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>WIKI</td>\n      <td>Growth Form</td>\n      <td>512</td>\n      <td>0.8736</td>\n      <td>0.865919</td>\n      <td>0.822443</td>\n      <td>0.838805</td>\n      <td>distilbert-base-uncased</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_results.to_excel(\"FewShotLearningTraitClassification_Encoder.xlsx\", index = False)","metadata":{"execution":{"iopub.status.busy":"2023-09-24T18:20:17.980302Z","iopub.execute_input":"2023-09-24T18:20:17.981384Z","iopub.status.idle":"2023-09-24T18:20:18.006550Z","shell.execute_reply.started":"2023-09-24T18:20:17.981347Z","shell.execute_reply":"2023-09-24T18:20:18.005616Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"## SetFit","metadata":{}},{"cell_type":"code","source":"if torch.cuda.is_available():  # Tell PyTorch to use the GPU. \n    device = torch.device(\"cuda\") \n    print('There are %d GPU(s) available.' % torch.cuda.device_count()) \n    print('We will use the GPU:', torch.cuda.get_device_name(0)) # If not...\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")\n    \nimport gc\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-09-24T18:31:57.363282Z","iopub.execute_input":"2023-09-24T18:31:57.363719Z","iopub.status.idle":"2023-09-24T18:31:57.708458Z","shell.execute_reply.started":"2023-09-24T18:31:57.363687Z","shell.execute_reply":"2023-09-24T18:31:57.707443Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"There are 1 GPU(s) available.\nWe will use the GPU: Tesla P100-PCIE-16GB\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"118"},"metadata":{}}]},{"cell_type":"code","source":"results_list = []\nFS_sample_sizes = [32, 128, 512]\nfor model_name, model_checkpoint in zip(model_names[:], checkpoint_names[:]):\n    for dataset_name in list(raw_datasets.keys())[:]:\n        for FS_sample_size in FS_sample_sizes:\n            print(model_name, dataset_name)\n\n            # Load a SetFit model from Hub\n            model = SetFitModel.from_pretrained(\"sentence-transformers/paraphrase-mpnet-base-v2\")\n            \n            train_dataset = Dataset.from_pandas(preprocessed_dataset_dict[dataset_name, focus_name, \"train\"].sample(FS_sample_size, random_state = 42))\n            eval_dataset = Dataset.from_pandas(preprocessed_dataset_dict[dataset_name, focus_name, \"validation\"])\n\n            # Create trainer\n            trainer = SetFitTrainer(\n                model=model,\n                train_dataset=train_dataset,\n                eval_dataset=eval_dataset,\n                loss_class=CosineSimilarityLoss,\n                metric=\"f1\",\n                metric_kwargs = {\"average\": \"macro\"},\n                batch_size=8,\n                num_iterations=20, \n                num_epochs=1, \n                column_mapping={\"text\": \"text\", \"labels\": \"label\"}\n            )\n            \n            trainer.train()\n            metrics = trainer.evaluate()\n\n            results_list.append([dataset_name, focus_name, FS_sample_size, 0, 0, 0, metrics[\"f1\"], model_checkpoint])\n\n            torch.cuda.empty_cache()\n            gc.collect()\n\n\ndf_results = pd.DataFrame(results_list, columns=[\"Dataset\", \"Trait\", \"Sample Size\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"Model\"])","metadata":{"execution":{"iopub.status.busy":"2023-09-24T18:48:31.525907Z","iopub.execute_input":"2023-09-24T18:48:31.526326Z","iopub.status.idle":"2023-09-24T20:21:53.884319Z","shell.execute_reply.started":"2023-09-24T18:48:31.526295Z","shell.execute_reply":"2023-09-24T20:21:53.883306Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"distilbert POWO\n","output_type":"stream"},{"name":"stderr","text":"model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\nApplying column mapping to training dataset\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating Training Pairs:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f25f06578984c3d81cb2cc3018697ce"}},"metadata":{}},{"name":"stderr","text":"***** Running training *****\n  Num examples = 1280\n  Num epochs = 1\n  Total optimization steps = 160\n  Total train batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c837acb62c7845bc892e337b80643a93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/160 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"526fe42f89dc4cbabf97def5a6af0ddf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a65656adc8774eea9c8b2702246b7614"}},"metadata":{}},{"name":"stderr","text":"Applying column mapping to evaluation dataset\n***** Running evaluation *****\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15b68ddeba4f42259d0f78dee748f397"}},"metadata":{}},{"name":"stdout","text":"distilbert POWO\n","output_type":"stream"},{"name":"stderr","text":"model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\nApplying column mapping to training dataset\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating Training Pairs:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e79955a89bd40da98f95d128026fab5"}},"metadata":{}},{"name":"stderr","text":"***** Running training *****\n  Num examples = 5120\n  Num epochs = 1\n  Total optimization steps = 640\n  Total train batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"582c21386a00475fb9cb1efb6bf45e69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/640 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0adb66b7ac56412d877c151e87297d71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"614a96b42a0d4daf88ae2b4b67ebca36"}},"metadata":{}},{"name":"stderr","text":"Applying column mapping to evaluation dataset\n***** Running evaluation *****\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe46bec9802d437e82ae5722bad2f50e"}},"metadata":{}},{"name":"stdout","text":"distilbert POWO\n","output_type":"stream"},{"name":"stderr","text":"model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\nApplying column mapping to training dataset\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating Training Pairs:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ddf7463124849a099c73a1e357a418a"}},"metadata":{}},{"name":"stderr","text":"***** Running training *****\n  Num examples = 20480\n  Num epochs = 1\n  Total optimization steps = 2560\n  Total train batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eef9dd786c124a1c9e671a28e6ad1458"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/2560 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89623722673f4aa6b164c8af3ff4c946"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/16 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebf7cb47d308479db759f0cdac948e77"}},"metadata":{}},{"name":"stderr","text":"Applying column mapping to evaluation dataset\n***** Running evaluation *****\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7def9df1ccb4d038e06481f282ad020"}},"metadata":{}},{"name":"stdout","text":"distilbert WIKI\n","output_type":"stream"},{"name":"stderr","text":"model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\nApplying column mapping to training dataset\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating Training Pairs:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c42a8377d20a4e81930fb66a9a213952"}},"metadata":{}},{"name":"stderr","text":"***** Running training *****\n  Num examples = 1280\n  Num epochs = 1\n  Total optimization steps = 160\n  Total train batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"746593b9d494404093deb15ae0e15010"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/160 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e513dcb08ff4a5bb4bc4d08925e1beb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f99b7d2caf14782985c286118362cce"}},"metadata":{}},{"name":"stderr","text":"Applying column mapping to evaluation dataset\n***** Running evaluation *****\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65801613a4d545b08a6eedeafcc17304"}},"metadata":{}},{"name":"stdout","text":"distilbert WIKI\n","output_type":"stream"},{"name":"stderr","text":"model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\nApplying column mapping to training dataset\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating Training Pairs:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88ca96916d6746e6867e68a115ee5514"}},"metadata":{}},{"name":"stderr","text":"***** Running training *****\n  Num examples = 5120\n  Num epochs = 1\n  Total optimization steps = 640\n  Total train batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee64759608ee4948afd1af893b8c5ca0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/640 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf54c56950b24a19be3da811c6038b3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af4a00127d1c422da11fed6a76d4ae7e"}},"metadata":{}},{"name":"stderr","text":"Applying column mapping to evaluation dataset\n***** Running evaluation *****\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00208f0815a645a3a574da0f6b77d7c1"}},"metadata":{}},{"name":"stdout","text":"distilbert WIKI\n","output_type":"stream"},{"name":"stderr","text":"model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\nApplying column mapping to training dataset\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating Training Pairs:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18aa53d31e0544c1b2d6ff83531649a6"}},"metadata":{}},{"name":"stderr","text":"***** Running training *****\n  Num examples = 20480\n  Num epochs = 1\n  Total optimization steps = 2560\n  Total train batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f53f3bce99844bd82911b01f34556c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/2560 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf802c1b2af34814a21f95994287efdc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/16 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9670eddf824f4eb5ac82cd1df5c03244"}},"metadata":{}},{"name":"stderr","text":"Applying column mapping to evaluation dataset\n***** Running evaluation *****\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15783f71e99b4612b922398af3750eed"}},"metadata":{}}]},{"cell_type":"code","source":"df_results","metadata":{"execution":{"iopub.status.busy":"2023-09-24T20:21:53.886329Z","iopub.execute_input":"2023-09-24T20:21:53.886711Z","iopub.status.idle":"2023-09-24T20:21:53.904448Z","shell.execute_reply.started":"2023-09-24T20:21:53.886676Z","shell.execute_reply":"2023-09-24T20:21:53.903115Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"  Dataset        Trait  Sample Size  Accuracy  Precision  Recall  F1-Score  \\\n0    POWO  Growth Form           32         0          0       0  0.306703   \n1    POWO  Growth Form          128         0          0       0  0.794675   \n2    POWO  Growth Form          512         0          0       0  0.835472   \n3    WIKI  Growth Form           32         0          0       0  0.519236   \n4    WIKI  Growth Form          128         0          0       0  0.821678   \n5    WIKI  Growth Form          512         0          0       0  0.829715   \n\n                     Model  \n0  distilbert-base-uncased  \n1  distilbert-base-uncased  \n2  distilbert-base-uncased  \n3  distilbert-base-uncased  \n4  distilbert-base-uncased  \n5  distilbert-base-uncased  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataset</th>\n      <th>Trait</th>\n      <th>Sample Size</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1-Score</th>\n      <th>Model</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>POWO</td>\n      <td>Growth Form</td>\n      <td>32</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.306703</td>\n      <td>distilbert-base-uncased</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>POWO</td>\n      <td>Growth Form</td>\n      <td>128</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.794675</td>\n      <td>distilbert-base-uncased</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>POWO</td>\n      <td>Growth Form</td>\n      <td>512</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.835472</td>\n      <td>distilbert-base-uncased</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>WIKI</td>\n      <td>Growth Form</td>\n      <td>32</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.519236</td>\n      <td>distilbert-base-uncased</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>WIKI</td>\n      <td>Growth Form</td>\n      <td>128</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.821678</td>\n      <td>distilbert-base-uncased</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>WIKI</td>\n      <td>Growth Form</td>\n      <td>512</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.829715</td>\n      <td>distilbert-base-uncased</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_results.to_excel(\"FewShotLearningTraitClassification_SetFit.xlsx\", index = False)","metadata":{"execution":{"iopub.status.busy":"2023-09-24T20:21:53.905749Z","iopub.execute_input":"2023-09-24T20:21:53.906608Z","iopub.status.idle":"2023-09-24T20:21:53.934260Z","shell.execute_reply.started":"2023-09-24T20:21:53.906563Z","shell.execute_reply":"2023-09-24T20:21:53.933379Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}