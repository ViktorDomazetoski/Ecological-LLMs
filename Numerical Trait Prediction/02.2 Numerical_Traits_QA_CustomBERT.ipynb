{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Math & Data Libraries'''\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Miscellaneous Libraries'''\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''NLP Libraries'''\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''String Libraries'''\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "font = {'family': 'serif',\n",
    "        'color':  '#333333',\n",
    "        'weight': 'normal',\n",
    "        'size': 14,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QA_Prediction(Questions, Description, model_pipeline):\n",
    "    if not isinstance(Description, str):\n",
    "        return \"\", \"No Description\", 0 \n",
    "    \n",
    "    answer_list = []\n",
    "    score_list = []\n",
    "    if(not any(map(str.isdigit, Description))):\n",
    "        return \"\", \"No Number\", 0\n",
    "    \n",
    "    for q_i, question in enumerate(Questions):\n",
    "        QA_input = {\n",
    "        'question': question,\n",
    "        'context': Description\n",
    "        }\n",
    "        res = model_pipeline(QA_input)\n",
    "        answer = res[\"answer\"]\n",
    "        score = np.round(res[\"score\"], 3)# if contain_check else 0\n",
    "        answer_list.append(answer)\n",
    "        score_list.append(score)\n",
    "        \n",
    "    best_answer_i = np.argmax(score_list)\n",
    "    best_question = Questions[best_answer_i]\n",
    "    best_answer = answer_list[best_answer_i]\n",
    "    best_score = score_list[best_answer_i]\n",
    "    \n",
    "    return best_question, best_answer, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_float(element):\n",
    "    try:\n",
    "        float(element)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_answer_height(answer):\n",
    "    available_units = ('mm', 'cm', 'm', 'km', 'inches', 'ft', 'yds', 'miles')\n",
    "    conversions = (1, 10, 1000, 1e6, 25.4, 304.8, 914.4, 1.609344e6)\n",
    "    conversion_dict = {unit:rate for unit, rate in zip(available_units, conversions)}\n",
    "    \n",
    "    flag = 0\n",
    "    answer_punc = answer.translate(str.maketrans('', '', string.punctuation))\n",
    "    for unit in available_units:\n",
    "        if(unit in answer_punc.split(\" \")):\n",
    "            flag = 1\n",
    "            metric = unit\n",
    "            break\n",
    "            \n",
    "    if(flag==0):\n",
    "        return \"No metric\"\n",
    "    result = []\n",
    "\n",
    "    answer = re.sub(\"\\(.*?\\)\",\"\",answer)\n",
    "\n",
    "    answer = answer.replace(\"-\", \" \") \n",
    "    counter = 0\n",
    "    for part in answer.split(\" \"):\n",
    "        if(counter>2):\n",
    "            return \"Too many numbers\"\n",
    "        if(is_float(part)):\n",
    "            tmp = str(np.round(float(part) * conversion_dict[metric]/1000, 4))\n",
    "            counter += 1\n",
    "            result.append(tmp)\n",
    "    return \" \".join(result)\n",
    "\n",
    "\n",
    "def post_process_answer_leaf_length(answer):\n",
    "    available_units = ('mm', 'cm', 'm', 'km', 'inches', 'ft', 'yds', 'miles')\n",
    "    conversions = (1, 10, 1000, 1e6, 25.4, 304.8, 914.4, 1.609344e6)\n",
    "    conversion_dict = {unit:rate for unit, rate in zip(available_units, conversions)}\n",
    "    \n",
    "    flag = 0\n",
    "    answer_punc = answer.translate(str.maketrans('', '', string.punctuation))\n",
    "    for unit in available_units:\n",
    "        if(unit in answer_punc.split(\" \")):\n",
    "            flag = 1\n",
    "            metric = unit\n",
    "            \n",
    "    if(flag==0):\n",
    "        return \"No metric\"\n",
    "    result = []\n",
    "\n",
    "    if(\"x\" in answer):\n",
    "        answer = answer.split(\"x\")[0]\n",
    "    \n",
    "    answer = re.sub(\"\\(.*?\\)\",\"\",answer)\n",
    "\n",
    "    answer = answer.replace(\"-\", \" \") \n",
    "    counter = 0\n",
    "    for part in answer.split(\" \"):\n",
    "        if(counter>2):\n",
    "            return \"Too many numbers\"\n",
    "        if(is_float(part)):\n",
    "            tmp = str(np.round(float(part) * conversion_dict[metric]/10, 4))\n",
    "            counter += 1\n",
    "            result.append(tmp)\n",
    "    return \" \".join(result)\n",
    "\n",
    "def post_process_answer_leaf_width(answer):\n",
    "    available_units = ('mm', 'cm', 'm', 'km', 'inches', 'ft', 'yds', 'miles')\n",
    "    conversions = (1, 10, 1000, 1e6, 25.4, 304.8, 914.4, 1.609344e6)\n",
    "    conversion_dict = {unit:rate for unit, rate in zip(available_units, conversions)}\n",
    "    \n",
    "    flag = 0\n",
    "    answer_punc = answer.translate(str.maketrans('', '', string.punctuation))\n",
    "    for unit in available_units:\n",
    "        if(unit in answer_punc.split(\" \")):\n",
    "            flag = 1\n",
    "            metric = unit\n",
    "            \n",
    "    if(flag==0):\n",
    "        return \"No metric\"\n",
    "    result = []\n",
    "\n",
    "    if(\"x\" in answer):\n",
    "        answer = answer.split(\"x\")[1]\n",
    "    \n",
    "    answer = re.sub(\"\\(.*?\\)\",\"\",answer)\n",
    "\n",
    "    answer = answer.replace(\"-\", \" \") \n",
    "    counter = 0\n",
    "    for part in answer.split(\" \"):\n",
    "        if(counter>2):\n",
    "            return \"Too many numbers\"\n",
    "        if(is_float(part)):\n",
    "            tmp = str(np.round(float(part) * conversion_dict[metric]/10, 4))\n",
    "            counter += 1\n",
    "            result.append(tmp)\n",
    "    return \" \".join(result)\n",
    "\n",
    "def post_post_process_answer(answer):\n",
    "    answer_parts = answer.split(\" \")\n",
    "    if(len(answer_parts)==1 and is_float(answer_parts[0])):\n",
    "        return float(answer_parts[0])\n",
    "    if(len(answer_parts)==2 and is_float(answer_parts[0]) and is_float(answer_parts[1])):\n",
    "        return float(answer_parts[1])\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plants of the World Online - POWO GIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict[\"POWO\"] = pd.read_excel(\"..//Datasets//POWO_GIFT.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom NUM BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "854e24fc904940ae8338e96244780f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/431M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a28c5a99384b82a6401b7794855c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/315 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b23134c59d40d9a27f2ccff901432d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e534dd0596541fcb78e333fafb877b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/669k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450169f4e7ae4b6a812d185b81631411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"ViktorDo/bert-finetuned-custom_Numerical_Traits\"\n",
    "nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)\n",
    "model_dict[\"CustomBERT\"] = nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_dict = dict()\n",
    "predictions_dict = dict()\n",
    "post_predictions_dict = dict()\n",
    "pred_mask_dict = dict()\n",
    "score_dict = dict()\n",
    "mask_dict = dict()\n",
    "true_dict = dict()\n",
    "description_dict = dict()\n",
    "Questions = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plant Height Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_name = \"Plant Height Max\"\n",
    "focus_code = \"1.6.2\"\n",
    "\n",
    "description_column = \"QA_description\"\n",
    "questions = [\"How tall is the plant?\", \"What is the height?\"]\n",
    "\n",
    "Questions[focus_name] = questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POWO Number of Species with Plant Height Max Information: 17648/59151 (0.3%)\n"
     ]
    }
   ],
   "source": [
    "for dataset in [\"POWO\"]:\n",
    "    mask_dict[focus_name] = df_dict[dataset][focus_code].notna()\n",
    "    print(\"{} Number of Species with {} Information: {}/{} ({}%)\".format(dataset, focus_name, np.sum(mask_dict[focus_name]), len(df_dict[dataset][focus_code]), np.round(np.sum(mask_dict[focus_name])/len(df_dict[dataset][focus_code]),2 )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17648it [9:00:06,  1.84s/it]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'post_process_answer_height' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     true_list\u001b[39m.\u001b[39mappend(trait_value)\n\u001b[0;32m     17\u001b[0m     description_list\u001b[39m.\u001b[39mappend(description)\n\u001b[1;32m---> 19\u001b[0m post_predictions \u001b[39m=\u001b[39m [post_process_answer_height(ans) \u001b[39mfor\u001b[39;00m ans \u001b[39min\u001b[39;00m answer_list]\n\u001b[0;32m     20\u001b[0m post_post_predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([post_post_process_answer(ans) \u001b[39mfor\u001b[39;00m ans \u001b[39min\u001b[39;00m post_predictions])\n\u001b[0;32m     21\u001b[0m pred_mask_v2 \u001b[39m=\u001b[39m post_post_predictions\u001b[39m!=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[19], line 19\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     16\u001b[0m     true_list\u001b[39m.\u001b[39mappend(trait_value)\n\u001b[0;32m     17\u001b[0m     description_list\u001b[39m.\u001b[39mappend(description)\n\u001b[1;32m---> 19\u001b[0m post_predictions \u001b[39m=\u001b[39m [post_process_answer_height(ans) \u001b[39mfor\u001b[39;00m ans \u001b[39min\u001b[39;00m answer_list]\n\u001b[0;32m     20\u001b[0m post_post_predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([post_post_process_answer(ans) \u001b[39mfor\u001b[39;00m ans \u001b[39min\u001b[39;00m post_predictions])\n\u001b[0;32m     21\u001b[0m pred_mask_v2 \u001b[39m=\u001b[39m post_post_predictions\u001b[39m!=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'post_process_answer_height' is not defined"
     ]
    }
   ],
   "source": [
    "for dataset in [\"POWO\"]:\n",
    "    for model in [\"CustomBERT\"]: \n",
    "        question_list = []\n",
    "        answer_list = []\n",
    "        score_list = []\n",
    "        true_list = []\n",
    "        description_list = []\n",
    "\n",
    "        mask_dict[focus_name] = df_dict[dataset][focus_code].notna()\n",
    "\n",
    "        for i, (description, trait_value) in tqdm(enumerate(df_dict[dataset][mask_dict[focus_name]][[description_column, focus_code]].values)):\n",
    "            ques, ans, score = QA_Prediction(Questions[focus_name], description, model_dict[model])\n",
    "            question_list.append(ques)\n",
    "            answer_list.append(ans)\n",
    "            score_list.append(score)\n",
    "            true_list.append(trait_value)\n",
    "            description_list.append(description)\n",
    "\n",
    "        post_predictions = [post_process_answer_height(ans) for ans in answer_list]\n",
    "        post_post_predictions = np.array([post_post_process_answer(ans) for ans in post_predictions])\n",
    "        pred_mask_v2 = post_post_predictions!=-1\n",
    "        \n",
    "        for var, data in zip([\"Questions\", \"Answers\", \"Scores\", \"Predictions\"], [question_list, answer_list, score_list, post_post_predictions]):\n",
    "            df_dict[dataset].loc[:, focus_code + \"_\" + var + \"_\" + model] = \"\"\n",
    "            df_dict[dataset].loc[mask_dict[focus_name], focus_code + \"_\" + var + \"_\" + model] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leaf Length Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_name = \"Leaf Length Max\"\n",
    "focus_code = \"4.6.2\"\n",
    "\n",
    "description_column = \"QA_description\"\n",
    "questions = [\"How long is the leaf?\", \"What is the leaf length?\"]\n",
    "\n",
    "Questions[focus_name] = questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POWO Number of Species with Leaf Length Max Information: 3397/59151 (0.06%)\n"
     ]
    }
   ],
   "source": [
    "for dataset in [\"POWO\"]:\n",
    "    mask_dict[focus_name] = df_dict[dataset][focus_code].notna()\n",
    "    print(\"{} Number of Species with {} Information: {}/{} ({}%)\".format(dataset, focus_name, np.sum(mask_dict[focus_name]), len(df_dict[dataset][focus_code]), np.round(np.sum(mask_dict[focus_name])/len(df_dict[dataset][focus_code]),2 )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3397it [2:49:57,  3.00s/it]\n"
     ]
    }
   ],
   "source": [
    "for dataset in [\"POWO\"]:\n",
    "    for model in [\"CustomBERT\"]: \n",
    "        question_list = []\n",
    "        answer_list = []\n",
    "        score_list = []\n",
    "        true_list = []\n",
    "        description_list = []\n",
    "\n",
    "        mask_dict[focus_name] = df_dict[dataset][focus_code].notna()\n",
    "\n",
    "        for i, (description, trait_value) in tqdm(enumerate(df_dict[dataset][mask_dict[focus_name]][[description_column, focus_code]].values)):\n",
    "            ques, ans, score = QA_Prediction(Questions[focus_name], description, model_dict[model])\n",
    "            question_list.append(ques)\n",
    "            answer_list.append(ans)\n",
    "            score_list.append(score)\n",
    "            true_list.append(trait_value)\n",
    "            description_list.append(description)\n",
    "\n",
    "        post_predictions = [post_process_answer_leaf_length(ans) for ans in answer_list]\n",
    "        post_post_predictions = np.array([post_post_process_answer(ans) for ans in post_predictions])\n",
    "        pred_mask_v2 = post_post_predictions!=-1\n",
    "        \n",
    "        for var, data in zip([\"Questions\", \"Answers\", \"Scores\", \"Predictions\"], [question_list, answer_list, score_list, post_post_predictions]):\n",
    "            df_dict[dataset].loc[:, focus_code + \"_\" + var + \"_\" + model] = \"\"\n",
    "            df_dict[dataset].loc[mask_dict[focus_name], focus_code + \"_\" + var + \"_\" + model] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leaf Width Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_name = \"Leaf Width Max\"\n",
    "focus_code = \"4.7.2\"\n",
    "\n",
    "description_column = \"QA_description\"\n",
    "questions = [\"How wide is the leaf?\", \"What is the leaf width?\"]\n",
    "\n",
    "Questions[focus_name] = questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POWO Number of Species with Leaf Width Max Information: 2243/59151 (0.04%)\n"
     ]
    }
   ],
   "source": [
    "for dataset in [\"POWO\"]:\n",
    "    mask_dict[focus_name] = df_dict[dataset][focus_code].notna()\n",
    "    print(\"{} Number of Species with {} Information: {}/{} ({}%)\".format(dataset, focus_name, np.sum(mask_dict[focus_name]), len(df_dict[dataset][focus_code]), np.round(np.sum(mask_dict[focus_name])/len(df_dict[dataset][focus_code]),2 )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2243it [1:32:11,  2.47s/it]\n"
     ]
    }
   ],
   "source": [
    "for dataset in [\"POWO\"]:\n",
    "    for model in [\"CustomBERT\"]: \n",
    "        question_list = []\n",
    "        answer_list = []\n",
    "        score_list = []\n",
    "        true_list = []\n",
    "        description_list = []\n",
    "\n",
    "        mask_dict[focus_name] = df_dict[dataset][focus_code].notna()\n",
    "\n",
    "        for i, (description, trait_value) in tqdm(enumerate(df_dict[dataset][mask_dict[focus_name]][[description_column, focus_code]].values)):\n",
    "            ques, ans, score = QA_Prediction(Questions[focus_name], description, model_dict[model])\n",
    "            question_list.append(ques)\n",
    "            answer_list.append(ans)\n",
    "            score_list.append(score)\n",
    "            true_list.append(trait_value)\n",
    "            description_list.append(description)\n",
    "\n",
    "        post_predictions = [post_process_answer_leaf_width(ans) for ans in answer_list]\n",
    "        post_post_predictions = np.array([post_post_process_answer(ans) for ans in post_predictions])\n",
    "        pred_mask_v2 = post_post_predictions!=-1\n",
    "        \n",
    "        for var, data in zip([\"Questions\", \"Answers\", \"Scores\", \"Predictions\"], [question_list, answer_list, score_list, post_post_predictions]):\n",
    "            df_dict[dataset].loc[:, focus_code + \"_\" + var + \"_\" + model] = \"\"\n",
    "            df_dict[dataset].loc[mask_dict[focus_name], focus_code + \"_\" + var + \"_\" + model] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [\"POWO\"]:\n",
    "    df_dict[dataset].to_excel(f\"Results//{dataset}_Numerical_Predictions_CustomBERT.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
